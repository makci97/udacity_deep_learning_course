{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from object_detection.utils import dataset_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_filename = \"./data/train/train.json\"\n",
    "test_filename = \"./data/test/test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_json(filename):\n",
    "    with open(filename) as json_data:\n",
    "        data = json.load(json_data)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = read_json(train_filename)\n",
    "test_data = read_json(test_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.png'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]['image_path'].split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_path': 'data/train/formated_data_192x64/1.png',\n",
       " 'labels': [1.0, 9.0],\n",
       " 'rects': [{'x1': 64.0, 'x2': 85.0, 'y1': 14.0, 'y2': 54.0},\n",
       "  {'x1': 84.0, 'x2': 109.0, 'y1': 15.0, 'y2': 55.0}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(b's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(bytes('filename.png', 'utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'filename'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes(bytes('filename.png', 'utf-8').decode('utf-8').replace('.png', ''), 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TFRecord format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FINAL_HEIGHT = 64\n",
    "FINAL_WIDTH = 192\n",
    "\n",
    "def create_tf_example(example):\n",
    "    height = FINAL_HEIGHT # Image height\n",
    "    width = FINAL_WIDTH # Image width\n",
    "    filename = bytes(example['image_path'], 'utf-8') # Filename of the image. Empty if image is not from file\n",
    "    encoded_image_data = tf.gfile.FastGFile(example['image_path'], 'rb').read() # Encoded image bytes\n",
    "    #Image.open(example['image_path'], 'r').tobytes()\n",
    "    image_format = b'png' # b'jpeg' or b'png'\n",
    "\n",
    "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = [] # List of integer class id of bounding box (1 per box)\n",
    "    \n",
    "    for rect, label in zip(example['rects'], example['labels']):\n",
    "        label = int(label)\n",
    "        xmins.append(rect['x1']/width)\n",
    "        xmaxs.append(rect['x2']/width)\n",
    "        ymins.append(rect['y1']/height)\n",
    "        ymaxs.append(rect['y2']/height)\n",
    "        if xmins[-1] < 0 or xmaxs[-1] > 1. or ymins[-1] < 0 or ymaxs[-1] > 1.:\n",
    "            raise Exception()\n",
    "        if xmaxs[-1] < 0 or xmins[-1] > 1. or ymaxs[-1] < 0 or ymins[-1] > 1.:\n",
    "            raise Exception()\n",
    "        classes_text.append(bytes(str(label), 'utf-8'))\n",
    "        classes.append(label if label != 0 else 10)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_TFRecord(examples, output_path):\n",
    "    counter = 0\n",
    "    with tf.python_io.TFRecordWriter(output_path) as writer:\n",
    "        for example in examples:\n",
    "            try:\n",
    "                tf_example = create_tf_example(example)\n",
    "                writer.write(tf_example.SerializeToString())\n",
    "            except:\n",
    "                counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_output_path = 'train.record'\n",
    "test_output_path = 'test.record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180\n",
      "CPU times: user 1min 27s, sys: 5.32 s, total: 1min 32s\n",
      "Wall time: 1min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_TFRecord(train_data, train_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "CPU times: user 29.9 s, sys: 1.93 s, total: 31.9 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_TFRecord(test_data, test_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert for images without resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tf_example(example):\n",
    "    img = Image.open(example['image_path'], 'r')\n",
    "    width, height = img.getbbox()[2:]\n",
    "    filename = bytes(example['image_path'], 'utf-8') # Filename of the image. Empty if image is not from file\n",
    "    encoded_image_data = tf.gfile.FastGFile(example['image_path'], 'rb').read() # Encoded image bytes\n",
    "    #Image.open(example['image_path'], 'r').tobytes()\n",
    "    image_format = b'png' # b'jpeg' or b'png'\n",
    "\n",
    "    xmins = [] # List of normalized left x coordinates in bounding box (1 per box)\n",
    "    xmaxs = [] # List of normalized right x coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    ymins = [] # List of normalized top y coordinates in bounding box (1 per box)\n",
    "    ymaxs = [] # List of normalized bottom y coordinates in bounding box\n",
    "             # (1 per box)\n",
    "    classes_text = [] # List of string class name of bounding box (1 per box)\n",
    "    classes = [] # List of integer class id of bounding box (1 per box)\n",
    "    \n",
    "    for rect, label in zip(example['rects'], example['labels']):\n",
    "        label = int(label)\n",
    "        xmins.append(rect['x1']/width)\n",
    "        xmaxs.append(rect['x2']/width)\n",
    "        ymins.append(rect['y1']/height)\n",
    "        ymaxs.append(rect['y2']/height)\n",
    "        if xmins[-1] < 0 or xmaxs[-1] > 1. or ymins[-1] < 0 or ymaxs[-1] > 1.:\n",
    "            raise Exception()\n",
    "        if xmaxs[-1] < 0 or xmins[-1] > 1. or ymaxs[-1] < 0 or ymins[-1] > 1.:\n",
    "            raise Exception()\n",
    "        classes_text.append(bytes(str(label), 'utf-8'))\n",
    "        classes.append(label if label != 0 else 10)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_image_data),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_without_resize_filename = \"./data/train/train_without_resize.json\"\n",
    "test_without_resize_filename = \"./data/test/test_without_resize.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_without_resize_data = read_json(train_without_resize_filename)\n",
    "test_without_resize_data = read_json(test_without_resize_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_without_resize_output_path = 'train_without_resize.record'\n",
    "test_without_resize_output_path = 'test_without_resize.record'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181\n",
      "CPU times: user 1min 51s, sys: 7.5 s, total: 1min 58s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_TFRecord(train_without_resize_data, train_without_resize_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "CPU times: user 49.8 s, sys: 3.21 s, total: 53 s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "write_TFRecord(test_without_resize_data, test_without_resize_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
